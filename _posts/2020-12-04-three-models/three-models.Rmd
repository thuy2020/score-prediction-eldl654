---
title: "Three models"
description: |
  Three models: fitting procedures and the results of model evaluation.
author:
  - name: Jim - Claire - Thuy
    url: https://www.uoregon.edu/
date: 12-04-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidymodels)
library(tune)
library(glmnet)
library(baguette)
library(parsnip)
library(doParallel)
library(vip)
library(pdp)
library(patchwork)
library(ranger)
library(future)
```

# Split and Resample 

```{r, include=TRUE}
set.seed(3000)
data_split <- initial_split(data, strata = "score")

set.seed(3000)
train <- training(data_split)
test <- testing(data_split)

set.seed(3000)
data_cv <- vfold_cv(train, strata = "score")

```


```{r, include=TRUE}
rec <- recipe(
    formula = score ~ ., data = train 
  ) %>%
 step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>%
 update_role(contains("id"), ncessch, sch_name, new_role = "id") %>%
 # step_novel(all_nominal(), -all_outcomes()) %>%
 step_unknown(all_nominal(), -all_outcomes()) %>%
 step_medianimpute(all_numeric()) %>%
 step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %>%
 step_dummy(all_nominal(), -has_role(match = "id"), -all_outcomes()) %>%
 step_nzv(all_predictors())

prep(rec)  
```

# Model 1: Decision tree

```{r, include=TRUE}
# 1. Tuning the cost complexity and minimum n 
tune_model <- decision_tree() %>% 
  set_mode("regression") %>% 
  set_engine("rpart") %>% 
  set_args(cost_complexity = tune(), 
           min_n = tune())

# 2. Tune your model with tune_grid

grd <- grid_regular(cost_complexity(), min_n(), levels = c(10, 5)) 
metrics_eval <- metric_set(rmse)

tictoc::tic()
tune_tree <- tune_grid(tune_model, 
                       rec, 
                       data_cv, 
                       grid = grd, 
                       metrics = metrics_eval)
tictoc::toc()
# 291.299 sec elapsed

# 4. Best Estimates 
collect_metrics(tune_tree) %>% 
  filter(.metric == "rmse") %>% 
  ggplot(aes(cost_complexity, mean))+
  geom_point(aes(color = factor(min_n)))
```

This plot shows that the lowest rmse is resulted from a combation of cost_complexity = 0.01 and min_n = 30

```{r}
#5. Using a specific values based on the plot above
collect_metrics(tune_tree) %>% 
  filter(cost_complexity == 0.01 & min_n == 30) %>% 
  ggplot(aes(cost_complexity, mean))+
  geom_point()
```

```{r}
final_decision_mod <- tune_model %>% 
  finalize_model(select_best(tune_tree, "rmse"))

final_fit_decision <- last_fit(final_decision_mod, rec, data_split)
collect_metrics(final_fit_decision)
```

# Model 2: Bagged Tree

## Model and Workflow

```{r, include=TRUE}
# 1. Create a parsnip bagged tree model using{baguette}
bag_mod_tune <- bag_tree() %>% 
  set_mode("regression") %>% 
  set_args(cost_complexity = tune(), min_n = tune()) %>% 
  set_engine("rpart", times = 10) 

# 2. Tune with tune_grid

tree_grid <- grid_max_entropy(cost_complexity(), min_n(), size = 10) 

plan(multisession) 
tictoc::tic()
bag_tune <- tune_grid(bag_model_tune,
                      rec,
                      data_cv,
                      grid = tree_grid) 
tictoc::toc() # 311.272 sec elapsed

# 4. Best hyper parameters
select_best(bag_tune, "rmse")
```

Finalize model 2
```{r}
final_bag_mod <- bag_mod_tune %>% 
  finalize_model(select_best(bag_tune, "rmse"))
```
Test fit model 2
```{r}
final_fit_bagtree <- last_fit(final_bag_mod, rec, data_split)
collect_metrics(final_fit_bagtree)
```

# Model 3: Random Forest 

```{r, include=TRUE}
(cores <- parallel::detectCores())

rf_def_mod <-
  rand_forest() %>% 
  set_engine("ranger",
             num.threads = cores, 
             importance = "permutation",  
             verbose = TRUE) %>% 
  set_mode("regression") %>% 
  set_args(mtry = tune(),
           trees = 1000,
           min_n = tune()) 

rf_wflow <- workflow() %>%
  add_model(rf_def_mod) %>% 
  add_recipe(rec)
```

## Fit

```{r, include=TRUE}
tictoc::tic()
set.seed(3000)
rf_def_res <- fit_resamples(
  rf_wflow,
  data_cv,
  metrics = metrics_eval,
  control = control_resamples(verbose = TRUE,
                            save_pred = TRUE,
                            extract = function(x) x))
tictoc::toc()

# Best Estimates 
#show_best(rf_def_res, "rmse")

```

# Make Predictions 

```{r, include=TRUE}
## Read and join full test data 
full_test <- read_csv(here::here("data", "train.csv"))

full_test_join <- left_join(full_test, ethnicities)
```

## Apply Fit Function to Workflow and Full Training 

```{r, include=TRUE}
tictoc::tic()
fit_rf_workflow <- fit(rf_wflow, train)
tictoc::toc()

fit_rf_workflow

sqrt(fit_rf_workflow$fit$fit$fit$prediction.error)
```

```{r, include=TRUE}
model_3_prediction <- predict(fit_rf_workflow, new_data = full_test_join)

head(model_3_prediction)
```

```{r, include=TRUE}
pred_frame <- tibble(Id = full_test_join$id, Predict = model_3_prediction$.pred)

head(pred_frame)
```

```{r, include=TRUE}
write_csv(pred_frame, "model_3_predictions.csv")
```

