---
title: "Three models"
description: |
  Three models: fitting procedures and the results of model evaluation.
author:
  - name: Jim - Claire - Thuy
    url: https://www.uoregon.edu/
date: 12-04-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidymodels)
library(tune)
library(glmnet)
library(baguette)
library(parsnip)
library(doParallel)
library(vip)
library(pdp)
library(patchwork)
library(ranger)
library(future)
library(rio)
library(bit64)
```

## Data

```{r, include=FALSE}
# load the given data
set.seed(3000)
data <- read_csv(here::here("data", "train.csv")) %>% 
  select(-classification)

data <- dplyr::sample_frac(data, size = 0.07) #trying 7% 

# get freelunch data

frl <- import("https://nces.ed.gov/ccd/Data/zip/ccd_sch_033_1718_l_1a_083118.zip",
              setclass = "tbl_df")  %>% 
  janitor::clean_names()  %>% 
  filter(st == "OR")  %>%
  select(ncessch, lunch_program, student_count)  %>% 
  mutate(student_count = replace_na(student_count, 0))  %>% 
  pivot_wider(names_from = lunch_program,
              values_from = student_count)  %>% 
  janitor::clean_names()  %>% 
  mutate(ncessch = as.double(ncessch))

stu_counts <- import("https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv",
                     setclass = "tbl_df")  %>% 
  filter(state == "OR" & year == 1718)  %>% 
  count(ncessch, wt = n)  %>% 
  mutate(ncessch = as.double(ncessch))

frl <- left_join(frl, stu_counts)

frl <- frl %>% 
 mutate(prop_frl = free_lunch_qualified / n,
       prop_reduced_lunch = reduced_price_lunch_qualified / n)

# ethnicities

sheets <- readxl::excel_sheets(here::here("data",
"fallmembershipreport_20192020.xlsx"))

ode_schools <- readxl::read_xlsx(here::here("data",
"fallmembershipreport_20192020.xlsx"), sheet = sheets[4])

ethnicities <- ode_schools %>%
select(attnd_schl_inst_id = `Attending School ID`,
sch_name = `School Name`,
contains("%")) %>%
janitor::clean_names()
names(ethnicities) <- gsub("x2019_20_percent", "p", names(ethnicities))

# join
data <- left_join(data, ethnicities)
data <- left_join(data, frl)
```

# Split and Resample 

```{r, include=TRUE}
set.seed(3000)
data_split <- initial_split(data, strata = "score")

set.seed(3000)
train <- training(data_split)
test <- testing(data_split)

set.seed(3000)
data_cv <- vfold_cv(train, strata = "score")

```


```{r, include=TRUE}
# this from model 1
rec <- recipe(score ~ ., train) %>% 
  step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %>% 
  update_role(contains("id"), ncessch, new_role = "id vars") %>% 
  step_novel(all_nominal()) %>%
  step_unknown(all_nominal()) %>%
  step_nzv(all_predictors()) %>%
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars")) %>%
  step_dummy(all_nominal(), -has_role("id vars")) %>%
  step_nzv(all_predictors()) %>% 
  step_interact(~lat:lon)

prep(rec)  
baked_train <- rec %>% prep() %>% bake(train)
baked_train
```

## Model 1: Linear Model 

```{r, include=TRUE} 
tictoc::tic()
final_mod <- linear_reg(penalty = tune(), 
                          mixture = tune())  %>% 
            set_engine("glmnet") %>%
            set_mode("regression")  

grid <- grid_regular(penalty(), mixture(), levels = c(10, 5))

final_mod_tuning <- tune_grid(final_mod, 
                              preprocessor = rec, 
                              resamples = data_cv, 
                              grid = grid, 
                              control = control_grid(verbose = TRUE))
tictoc::toc()

collect_metrics(final_mod_tuning) 

linear_mod <- final_mod_tuning %>% # 90.66920	
    show_best(metric = "rmse", n = 1)
```

## Model 1 Summary 


# Model 2: Decision tree

```{r, include=TRUE}
# 1. Tuning the cost complexity and minimum n 
tune_model <- decision_tree() %>% 
  set_mode("regression") %>% 
  set_engine("rpart") %>% 
  set_args(cost_complexity = tune(), 
           min_n = tune())

# 2. Tune your model with tune_grid

grd <- grid_regular(cost_complexity(), min_n(), levels = c(10, 5)) 
metrics_eval <- metric_set(rmse)

tictoc::tic()
tune_tree <- tune_grid(tune_model, 
                       rec, 
                       data_cv, 
                       grid = grd, 
                       metrics = metrics_eval)
tictoc::toc()
# 291.299 sec elapsed

# 4. Best Estimates 
collect_metrics(tune_tree) %>% 
  filter(.metric == "rmse") %>% 
  ggplot(aes(cost_complexity, mean))+
  geom_point(aes(color = factor(min_n)))

# Check again, but remove highest one Add some jitter to avoid overlap
collect_metrics(tune_tree) %>%  
  filter(.metric == "rmse" & cost_complexity != 0.1) %>% 
  ggplot(aes(cost_complexity, mean))+
  geom_jitter(aes(color = factor(min_n)),
              height = 0, width = 0.01)

# ==> this shows that we can get to rmse as small as 100.8179	. Now try to tune grid again to make it smaller

grid_min_n <- tibble(min_n = 10:40)

dt_tune2 <- tune_model %>% 
  set_args(cost_complexity = 0.01)

tictoc::tic()
dt_tune_fit2 <- tune_grid(
  dt_tune2,
  preprocessor = rec,
  resamples = data_cv,
  grid = grid_min_n
)
tictoc::toc()

# look at metric again after re-tune
show_best(dt_tune_fit2, metric = "rmse") # hoorayy, we got a tiny bit smaller. rmse = 96.21461. Life is hard, just accept it for now. 

#If we take 5% data, the rmse still 96. 
```

finalize the decision tree model 
```{r}
# set the final model parameters
best_params <- select_best(dt_tune_fit2, metric = "rmse")
final_mod_dt <- finalize_model(dt_tune2, best_params)
final_mod_dt

# use original `initial_split()` object
final_fit_dt <- last_fit(final_mod_dt, 
                         rec, 
                         data_split)
final_fit_dt
# view metrics

final_fit_dt$.metrics[[1]] # 95.6019768	

# prediction
predictions <- final_fit_dt$.predictions[[1]] # not so amazing though. The prediction is quite off. Well, it's a pandemic year :( 
predictions
```

# Model 2: Bagged Tree

```{r, include=TRUE}
# 1. set model 

bt_mod <- bag_tree() %>% 
  set_mode("regression") %>% 
  set_args(cost_complexity = tune(), min_n = tune()) %>% 
  set_engine("rpart", times = 50) # you will almost surely need more than 10


# fit to $k$ folds
tictoc::tic() 
bt_fit1 <- fit_resamples(bt_mod,
                       preprocessor = rec,
                       resamples = data_cv)
tictoc::toc() 

collect_metrics(bt_fit1)
# 2. Tune with tune_grid

tree_grid <- grid_max_entropy(cost_complexity(), min_n(), size = 10) 

plan(multisession) 
tictoc::tic()
bag_tune <- tune_grid(bag_mod_tune,
                      rec,
                      data_cv,
                      grid = tree_grid) 
tictoc::toc() # 311.272 sec elapsed

# 4. Best hyper parameters
select_best(bag_tune, "rmse")

# You should be doing more tuning than this. You need to actually evaluate your
# hyperparameters and see if there are trends and areas you need to do more
# detailed searches in. The space filling designs should just be a starting 
# point. They should give you a good approximation of hyperparamter combinations
# that work well, but you need to do more refined tuning  to find the best 
# combination
```

Finalize model 2
```{r}
final_bag_mod <- bag_mod_tune %>% 
  finalize_model(select_best(bag_tune, "rmse"))
```
Test fit model 2
```{r}
final_fit_bagtree <- last_fit(final_bag_mod, rec, data_split)
collect_metrics(final_fit_bagtree)
plan(sequential)
```

# Model 3: Random Forest 

```{r, include=TRUE}
cores <- parallel::detectCores()

rf_def_mod <-
  rand_forest() %>% 
  set_engine("ranger",
             num.threads = cores, 
             importance = "permutation",  
             verbose = TRUE) %>% 
  set_mode("regression") %>% 
  set_args(mtry = tune(),
           trees = 1000,
           min_n = tune()) 

rf_wflow <- workflow() %>%
  add_model(rf_def_mod) %>% 
  add_recipe(rec)
```

## Fit

```{r, include=TRUE}
# You have not setup a grid to search over. You have two parameters here to tune
# but you're moving to `fit_resamples()` instead of `tune_grid()`
# tictoc::tic()
# set.seed(3000)
# rf_def_res <- fit_resamples(
#   rf_wflow,
#   data_cv,
#   metrics = metrics_eval,
#   control = control_resamples(verbose = TRUE,
#                             save_pred = TRUE,
#                             extract = function(x) x))
# tictoc::toc()

# you should actually create a grid (probably start with a space filling 
# design and then go from there, as described above) but for now I'll just 
# do it with 10 values

tictoc::tic()
set.seed(3000)
rf_def_res <- tune_grid(
  rf_wflow,
  data_cv,
  metrics = metrics_eval,
  control = control_resamples(verbose = TRUE,
                            save_pred = TRUE,
                            extract = function(x) x))
tictoc::toc()

# Best Estimates 
show_best(rf_def_res, "rmse")

```

# Make Predictions 

```{r, include=TRUE}
## Read and join full test data 
full_test <- read_csv(here::here("data", "train.csv"))

full_test_join <- left_join(full_test, ethnicities)
```

## Apply Fit Function to Workflow and Full Training 

```{r, include=TRUE}
# You need to finalize your model before you can do the below because you have
# arguments that are set to `tune()`. They need actual values first.

# tictoc::tic()
# fit_rf_workflow <- fit(rf_wflow, train)
# tictoc::toc()

# fit_rf_workflow

# sqrt(fit_rf_workflow$fit$fit$fit$prediction.error)
```

```{r, include=TRUE}
# model_3_prediction <- predict(fit_rf_workflow, new_data = full_test_join)
# 
# head(model_3_prediction)
```

```{r, include=TRUE}
# pred_frame <- tibble(Id = full_test_join$id, Predict = model_3_prediction$.pred)
# 
# head(pred_frame)
```

```{r, include=TRUE}
# write_csv(pred_frame, "model_3_predictions.csv")
```

